# -*- coding: utf-8 -*-
"""product expiry prediction,.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17As1GI6nuAZeQ2hTevTDYilzKvFaBZbP
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib as matplotlib
import seaborn as sns
import plotly.express as px
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
# %matplotlib inline


sns.set_style("darkgrid")
matplotlib.rcParams['font.size']=14
matplotlib.rcParams['figure.figsize']=(10,5)

from google.colab import drive
drive.mount('/content/drive')
file_path="/content/drive/MyDrive/Colab Notebooks/Datasets/inventory_data.csv"
df=pd.read_csv(file_path,encoding='latin1')
df

df['timestamp'] = pd.to_datetime(df['timestamp'])
df['expiry_date'] = pd.to_datetime(df['expiry_date'])
df['manufacture_date'] = pd.to_datetime(df['manufacture_date'])

"""**Compute product shelf life (expiry_date - manufacture_date) in days**"""

df['shelf_life_days'] = (df['expiry_date'] - df['manufacture_date']).dt.days

print(df.info())

print(df.describe())

"""**Convert dates**"""

df['manufacture_date'] = pd.to_datetime(df['manufacture_date'])
df['expiry_date'] = pd.to_datetime(df['expiry_date'])
df['timestamp'] = pd.to_datetime(df['timestamp'])

"""**Percentage of missing values**"""

missing_pct = df.isnull().mean() * 100
print(missing_pct[missing_pct > 0])

"""**correlation of numeric columns**"""

numeric_cols = ['qty_in', 'qty_out', 'current_stock', 'price', 'shelf_life_days']

sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

"""**Feature: shelf life in days**"""

df['shelf_life_days'] = (df['expiry_date'] - df['manufacture_date']).dt.days

print(df[['sku_id', 'manufacture_date', 'expiry_date', 'shelf_life_days']].head())

"""** Distribution**"""

sns.histplot(df['shelf_life_days'], bins=50, kde=True)
plt.title("Distribution of Shelf Life (Days)")
plt.show()

"""**Boxplot by SKU**"""

plt.figure(figsize=(15,5))
sns.boxplot(x='sku_id', y='shelf_life_days', data=df)
plt.title("Shelf Life by SKU")
plt.xticks(rotation=90)
plt.show()

"""**Feature Engineering**"""

# Extract features
df['manufacture_year'] = df['manufacture_date'].dt.year
df['manufacture_month'] = df['manufacture_date'].dt.month
df['manufacture_day'] = df['manufacture_date'].dt.day

features = ['sku_id', 'batch_id', 'location', 'manufacture_year', 'manufacture_month', 'manufacture_day']
target = 'shelf_life_days'

"""**Preprocessing**"""

from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler
from sklearn.impute import SimpleImputer

# Split numeric and categorical
numeric_cols = ['manufacture_year', 'manufacture_month', 'manufacture_day']
categorical_cols = ['sku_id', 'batch_id', 'location']

X = df[features]
y = df[target]

# Impute missing categorical
X[categorical_cols] = X[categorical_cols].fillna("Unknown")

# Encode categorical
encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
X[categorical_cols] = encoder.fit_transform(X[categorical_cols])

# Impute numeric and scale
imputer = SimpleImputer(strategy='mean')
X[numeric_cols] = imputer.fit_transform(X[numeric_cols])
scaler = MinMaxScaler()
X[numeric_cols] = scaler.fit_transform(X[numeric_cols])

"""**Train Model**"""

import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LightGBM Regressor
model = lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.05, max_depth=10)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluate
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"MAE: {mae:.2f}, RMSE: {rmse:.2f}, RÂ²: {r2:.4f}")

"""**Save Pipeline**"""

import joblib

pipeline = {
    'model': model,
    'encoder': encoder,
    'imputer': imputer,
    'scaler': scaler,
    'features': features,
    'numeric_cols': numeric_cols,
    'categorical_cols': categorical_cols
}

joblib.dump(pipeline, "expiry_pipeline.joblib")

"""**Preprocess New Data for Prediction**"""

def preprocess_new(df, pipeline):
    df['manufacture_year'] = df['manufacture_date'].dt.year
    df['manufacture_month'] = df['manufacture_date'].dt.month
    df['manufacture_day'] = df['manufacture_date'].dt.day

    X = df[pipeline['features']].copy()

    # Categorical
    X[pipeline['categorical_cols']] = X[pipeline['categorical_cols']].fillna("Unknown")
    X[pipeline['categorical_cols']] = pipeline['encoder'].transform(X[pipeline['categorical_cols']])

    # Numeric
    X[pipeline['numeric_cols']] = pipeline['imputer'].transform(X[pipeline['numeric_cols']])
    X[pipeline['numeric_cols']] = pipeline['scaler'].transform(X[pipeline['numeric_cols']])

    return X

# Example
new_df = pd.DataFrame([{
    'sku_id': 'SKU123',
    'batch_id': 'BATCH01',
    'location': 'WarehouseA',
    'manufacture_date': pd.to_datetime("2025-11-28")
}])
X_new = preprocess_new(new_df, pipeline)
pred_shelf_life = pipeline['model'].predict(X_new)[0]

pred_expiry_date = new_df['manufacture_date'][0] + pd.Timedelta(days=int(pred_shelf_life))
print(f"Predicted Expiry Date: {pred_expiry_date.date()}")

"""**Gradio UI for Expiry Prediction**"""

import gradio as gr
import pandas as pd
import joblib

# Load pipeline
pipeline = joblib.load("expiry_pipeline.joblib")

# Preprocess for batch
def preprocess_new(df, pipeline):
    df['manufacture_year'] = df['manufacture_date'].dt.year
    df['manufacture_month'] = df['manufacture_date'].dt.month
    df['manufacture_day'] = df['manufacture_date'].dt.day

    X = df[pipeline['features']].copy()

    # Categorical
    X[pipeline['categorical_cols']] = X[pipeline['categorical_cols']].fillna("Unknown")
    X[pipeline['categorical_cols']] = pipeline['encoder'].transform(X[pipeline['categorical_cols']])

    # Numeric
    X[pipeline['numeric_cols']] = pipeline['imputer'].transform(X[pipeline['numeric_cols']])
    X[pipeline['numeric_cols']] = pipeline['scaler'].transform(X[pipeline['numeric_cols']])

    return X

# Batch prediction function
def batch_predict_expiry(file):
    df = pd.read_csv(file.name)
    df['manufacture_date'] = pd.to_datetime(df['manufacture_date'])

    # Predict shelf life
    X_new = preprocess_new(df, pipeline)
    shelf_life = pipeline['model'].predict(X_new)
    df['predicted_shelf_life_days'] = shelf_life.astype(int)
    df['predicted_expiry_date'] = df['manufacture_date'] + pd.to_timedelta(df['predicted_shelf_life_days'], unit='D')

    # Summary stats
    summary = f"Total Products: {len(df)}\n" \
              f"Average Shelf Life: {df['predicted_shelf_life_days'].mean():.2f} days\n" \
              f"Minimum Shelf Life: {df['predicted_shelf_life_days'].min()} days\n" \
              f"Maximum Shelf Life: {df['predicted_shelf_life_days'].max()} days"

    return df[['sku_id','batch_id','location','manufacture_date','predicted_shelf_life_days','predicted_expiry_date']], summary

# Gradio UI
demo = gr.Interface(
    fn=batch_predict_expiry,
    inputs=gr.File(label="Upload Inventory CSV (.csv)"),
    outputs=[
        gr.Dataframe(label="Predicted Expiry Dates"),
        gr.Textbox(label="Summary Statistics")
    ],
    title="Batch Product Expiry Predictor",
    description="""
Upload your inventory CSV with columns:
- sku_id
- batch_id
- location
- manufacture_date (YYYY-MM-DD)

The system predicts shelf life (days) and expiry date for each product.
"""
)

demo.launch()